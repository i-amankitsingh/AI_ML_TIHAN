Lecture Notes: Regression Model Evaluation & Multiple Linear Regression
ğŸŒŸ 1. What Is Regression?
Regression is a method used when we want to predict numbers.

It helps us find patterns between input factors (like hours studied) and outcomes (like marks scored).

ğŸ§  Think of it like saying:

â€œIf I know how much you study, sleep, and attend classes â€” can I guess your score?â€

Itâ€™s not about â€œyesâ€ or â€œnoâ€ â€” itâ€™s about how much or how many.

ğŸªœ 2. From Simple to Multiple Regression
ğŸ”¹ Simple Regression
When thereâ€™s one input and one output, we call it simple regression.

Example: Predicting a personâ€™s weight based only on their height.

But in real life, outcomes depend on many things, not just one.

ğŸ”¹ Multiple Regression
When there are many input factors, it becomes Multiple Linear Regression (MLR).

Example:

Predicting car mileage (km/l) depends on:

Engine size
Car weight
Fuel type
Number of gears
Air conditioning (yes/no)
Each of these features contributes differently.

MLR helps combine them all to give one best possible prediction.

ğŸš€ 3. Why Multiple Regression Is Useful
Multiple regression gives a complete picture.

Letâ€™s say youâ€™re trying to predict a studentâ€™s performance.

Depending only on study hours may not be enough â€” you also need:

Sleep hours
Attendance
Number of assignments completed
Each factor tells a small part of the story.

Together, they help you predict more accurately.

Thatâ€™s why MLR is widely used in:

Marketing â†’ predicting sales based on price, ads, and discounts
Healthcare â†’ predicting blood pressure using age, weight, and activity
Finance â†’ predicting loan defaults based on income and credit score
âš–ï¸ 4. Checking How Good the Model Is
After building a regression model, we must ask:

ğŸ‘‰ â€œIs my model actually good at predicting?â€

We measure this using evaluation metrics.

Hereâ€™s how to think of them in simple terms:

ğŸ§¾ Mean Absolute Error (MAE)
Imagine you guessed everyoneâ€™s marks and compared them with the real ones.

MAE tells you, on average, how far your guesses were from reality.

Smaller MAE â†’ better model.

ğŸ” Mean Squared Error (MSE)
This one is like MAE but gives extra punishment for big mistakes.

Itâ€™s helpful when large errors are costly â€” like predicting hospital bills.

ğŸ¯ Root Mean Squared Error (RMSE)
Think of it as a â€œstandard mistake sizeâ€ your model makes.

Itâ€™s in the same units as the target (e.g., rupees, kilometers, etc.),

so itâ€™s easier to explain to non-technical people.

ğŸ“ˆ R-squared (RÂ²)
This tells you how much of the outcome your model explains.

If RÂ² = 0.9, it means your model explains 90% of whatâ€™s going on â€” pretty good!

If RÂ² is low, the model is missing some key factors.

âš™ï¸ Adjusted R-squared
When you add more variables, RÂ² always increases â€”

even if those variables donâ€™t help.

Adjusted RÂ² fixes that by growing only when the new variable truly adds value.

ğŸ§  5. A Quick Scenario
Imagine youâ€™re a restaurant owner trying to predict monthly sales.

You consider:

Number of ads posted
Average food price
Customer reviews
Weather condition (sunny or rainy)
After training your regression model, you check how close the predicted sales are to actual sales.

If your predictions are mostly close â€” small average error, high RÂ² â€”

your model is doing a great job!

If your predictions are often way off, or your RÂ² is low â€”

the model may need better features, more data, or simpler relationships.

ğŸª 6. Common Issues in Regression
ğŸš§ Overfitting
Your model fits the training data too well â€” like memorizing answers instead of learning concepts.

It works perfectly on old data but performs poorly on new data.

You can spot it when training accuracy is high but test accuracy is low.

ğŸª« Underfitting
Your model is too simple â€” it misses key relationships.

This happens when you ignore important variables or use a weak model.

Both training and test accuracy will be low.

âœ… Goal: A balanced model that performs well on both training and unseen data.

ğŸ” 7. How to Improve Regression Models
Remove unnecessary features that add noise.
Standardize or scale numeric values so that all features have equal impact.
Check for correlated inputs â€” if two features are almost the same, drop one.
Use cross-validation â€” test your model on small unseen parts of data before finalizing.
Collect better data â€” sometimes the issue is not the model but poor data quality.