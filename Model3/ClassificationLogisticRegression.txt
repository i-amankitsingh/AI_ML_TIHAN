ntroduction to Classification with Logistic Regression
Prerequisites: Understanding of Python basics (variables, functions, lists), familiarity with linear regression concepts (what a prediction model does, idea of fitting a line to data), and basic probability (what percentages and probabilities mean).

Time to complete: 35-45 minutes

What you'll be able to do:

Explain how logistic regression predicts probabilities instead of continuous values
Apply the sigmoid function to convert any number into a probability between 0 and 1
Interpret decision boundaries and tune thresholds to optimize classification decisions
1. Introduction: What is Classification and Why Should You Care?
Core Definition
Classification is a type of supervised learning where we predict which category or class something belongs to, rather than predicting a number. Unlike regression (which predicts continuous values like house prices or temperatures), classification predicts discrete labels like "spam or not spam," "disease present or absent," or "customer will buy or won't buy." Logistic regression is one of the most fundamental classification algorithms that predicts the probability of something belonging to a particular class.

A Simple Analogy
Think of classification like a bouncer at a club checking IDs. The bouncer doesn't tell you "you're 0.73 years old enough"—they make a yes/no decision: you either get in or you don't. However, internally, they might be thinking "this person is 95% likely to be over 21 based on their appearance and ID," then using that confidence to make the final call. This analogy works for understanding the probability-to-decision process, but breaks down when considering that real classification problems often have much more complex decision criteria than a simple age threshold.

Why This Matters to You
Problem it solves: Many real-world decisions are binary or categorical. You need to decide "will this customer churn?", "is this email spam?", "is this transaction fraudulent?" You can't use linear regression for these because it would predict impossible values like "this email is 150% spam" or "this customer is -0.3 likely to buy."

What you'll gain:

Build prediction systems for yes/no decisions: You'll be able to create models that make categorical predictions with confidence scores, which is essential for most business applications.
Understand probability-based decision making: You'll learn how to convert raw model outputs into actionable decisions by tuning thresholds based on business needs.
Foundation for advanced classification: Logistic regression is the building block for understanding neural networks, where the sigmoid function appears repeatedly.
Real-world context: This is what email providers use to filter spam, what banks use to detect fraudulent transactions, and what healthcare systems use to flag patients at risk of disease.

2. The Foundation: Core Concepts Explained
Note: We'll build these concepts step by step—first understanding why we need something special for classification, then how the sigmoid function solves that problem, and finally how we make actual decisions.

Concept A: Why Linear Regression Fails for Classification
Definition: Linear regression predicts a continuous output by fitting a straight line through data points. For classification tasks, this approach breaks down because it can predict values outside the valid probability range of 0 to 1, and small changes in input can cause erratic threshold crossing.

Key characteristics:

Unbounded outputs: Linear regression can output any value from negative infinity to positive infinity (e.g., -2.5 or 158)
No probability interpretation: A prediction of 1.8 doesn't mean "180% likely"—it's meaningless for classification
Sensitive to outliers: Extreme data points can tilt the line, causing incorrect classifications for most of the data
A concrete example: If you try to predict whether a student passes (1) or fails (0) based on study hours using linear regression, studying 15 hours might predict 1.6 (impossible—you can't be "160% likely to pass").

Common confusion: Beginners think "I can just round the output to 0 or 1." The problem isn't just the final number—it's that the model doesn't learn the right decision boundary because it's optimized for minimizing numerical distance, not maximizing classification accuracy.

Concept B: The Sigmoid Function (The S-Curve)
Definition: The sigmoid function (also called the logistic function) is a mathematical transformation that squashes any input value into an output between 0 and 1. It's defined as σ(z) = 1 / (1 + e^(-z)), where z can be any real number and e is Euler's number (≈2.718).

How it relates to linear regression: Instead of outputting z = mx + b directly, logistic regression feeds that linear output through the sigmoid: output = σ(mx + b). This takes the unbounded linear prediction and compresses it into a valid probability.

Key characteristics:

S-shaped curve: Gradually transitions from 0 to 1, with the steepest change at the midpoint
Outputs always between 0 and 1: No matter what z value you input, the result is a valid probability
Interpretable as probability: An output of 0.75 means "75% confident this belongs to class 1"
A concrete example:

sigmoid(-10) ≈ 0.00005 (virtually 0)
sigmoid(0) = 0.5 (exactly in the middle)
sigmoid(10) ≈ 0.99995 (virtually 1)
Remember: This is similar to how you learned that dividing by increasingly large numbers approaches zero, but never quite reaches it. The sigmoid has that same asymptotic behavior at both extremes.

Concept C: Decision Boundaries and Thresholds
Definition: A decision boundary is the line (or surface in higher dimensions) that separates regions where the model predicts different classes. A threshold is the probability cutoff we choose to convert probabilities into final class predictions—typically 0.5, but adjustable based on business needs.

How it relates to the Sigmoid Function: The sigmoid gives us probabilities, but we need to convert them to decisions. The threshold determines where we draw the line: "if probability ≥ threshold, predict class 1; otherwise, predict class 0."

Key characteristics:

The 0.5 default: When the sigmoid output equals 0.5, the input z equals 0, meaning the model is perfectly uncertain
Adjustable based on costs: If false positives are expensive (e.g., unnecessary surgery), use a higher threshold like 0.7
Affects precision/recall tradeoff: Higher thresholds mean fewer positive predictions (more conservative), lower thresholds mean more positive predictions (more aggressive)
A concrete example: In spam detection, if you use threshold = 0.5, an email with 0.51 probability gets marked as spam. If you change threshold to 0.8, only emails with ≥80% spam probability get filtered, reducing false positives but potentially letting more spam through.

Common confusion: Beginners think the threshold is part of the model's training. Actually, the model learns to output probabilities during training, and we choose the threshold afterward based on what mistakes we can tolerate in production.

How These Concepts Work Together
The linear part (z = mx + b) captures patterns in your features, the sigmoid transforms that into a probability, and the threshold converts that probability into a final yes/no decision. Think of z as the "raw evidence score" (which can be any number), the sigmoid as a "confidence converter" (turning evidence into probability), and the threshold as your "decision policy" (the rule for how confident you need to be before saying "yes").

3. Seeing It in Action: Worked Examples
Tip: Study these examples carefully before attempting the practice task. Understanding why each step is taken is more important than memorizing the steps.

Example 1: The Basic Case - Single Feature Classification
Scenario: You're building a simple spam detector that looks at only one feature: the number of exclamation marks in an email. Let's say you've trained a model and it learned these parameters: z = -2 + 0.5 × (num_exclamation_marks).

Our approach: We'll calculate the probability for a few different emails and see how the sigmoid transforms the linear score into probabilities. This demonstrates the core mechanics without getting lost in multi-feature complexity.

Step-by-step solution:

import math

def sigmoid(z):
    """Convert any number to a probability between 0 and 1"""
    return 1 / (1 + math.exp(-z))

# Email 1: 0 exclamation marks
z1 = -2 + 0.5 * 0  # Raw score: -2
prob1 = sigmoid(z1)  # Transform to probability
print(f"0 exclamation marks: z={z1}, probability={prob1:.4f}")

# Email 2: 4 exclamation marks (the tipping point)
z2 = -2 + 0.5 * 4  # Raw score: 0
prob2 = sigmoid(z2)  # Exactly 0.5 when z=0
print(f"4 exclamation marks: z={z2}, probability={prob2:.4f}")

# Email 3: 10 exclamation marks
z3 = -2 + 0.5 * 10  # Raw score: 3
prob3 = sigmoid(z3)  # High confidence spam
print(f"10 exclamation marks: z={z3}, probability={prob3:.4f}")

Output:

0 exclamation marks: z=-2, probability=0.1192
4 exclamation marks: z=0, probability=0.5000
10 exclamation marks: z=3, probability=0.9526

What just happened: Notice how the sigmoid squeezed all three z-scores into the 0-1 range. The email with 4 exclamation marks sits exactly at the decision boundary (z=0, probability=0.5), while emails below and above that point have clear probabilities. The model learned that 4 exclamation marks is the tipping point between spam and not-spam based on the training data.

Check your understanding: Why does z=0 always correspond to probability=0.5, regardless of what your features are?

Example 2: Making Decisions with Different Thresholds
Scenario: You're running an online store and using logistic regression to predict whether a user will make a purchase. Your model outputs probabilities, but now you need to decide: at what probability threshold should you show an aggressive "limited time offer" popup?

What's different: Now we're not just calculating probabilities—we're making business decisions by choosing thresholds based on the costs of different mistakes.

Solution:

# Three users with different purchase probabilities
users = [
    {"id": "User_A", "probability": 0.35},
    {"id": "User_B", "probability": 0.62},
    {"id": "User_C", "probability": 0.89}
]

def make_prediction(prob, threshold):
    """Apply threshold to convert probability to decision"""
    return "Show Popup" if prob >= threshold else "Don't Show"

# Try different thresholds
thresholds = [0.3, 0.5, 0.7]

for threshold in thresholds:
    print(f"\n--- Using Threshold: {threshold} ---")
    for user in users:
        decision = make_prediction(user["probability"], threshold)
        print(f"{user['id']} (p={user['probability']}): {decision}")

Output:

--- Using Threshold: 0.3 ---
User_A (p=0.35): Show Popup
User_B (p=0.62): Show Popup
User_C (p=0.89): Show Popup

--- Using Threshold: 0.5 ---
User_A (p=0.35): Don't Show
User_B (p=0.62): Show Popup
User_C (p=0.89): Show Popup

--- Using Threshold: 0.7 ---
User_A (p=0.35): Don't Show
User_B (p=0.62): Don't Show
User_C (p=0.89): Show Popup

Key lesson: The model's probabilities stay the same—only our decision policy changes. With threshold=0.3, we're aggressive (show popup to almost everyone, risk annoying users who won't buy). With threshold=0.7, we're conservative (only show to highly likely buyers, but miss potential sales). The right choice depends on your business context: are you more worried about annoying users or missing sales opportunities?

Example 3: Real-World Application - Medical Diagnosis
Background: A hospital wants to use logistic regression to predict whether a patient has a particular disease based on test results. The model has been trained on historical patient data and outputs probabilities.

The challenge: False negatives (missing a disease) can be life-threatening, while false positives mean unnecessary follow-up tests that are stressful but not dangerous. How should they set their threshold?

The approach: They need a threshold that errs on the side of caution. Let's see how different thresholds affect their decisions for three patients:

# Patient test results after model prediction
patients = [
    {"name": "Patient 1", "test_score": -1.5, "age": 45, "symptoms": "mild"},
    {"name": "Patient 2", "test_score": 0.8, "age": 67, "symptoms": "moderate"},
    {"name": "Patient 3", "test_score": 2.3, "age": 72, "symptoms": "severe"}
]

# Convert test scores to probabilities
for patient in patients:
    z = patient["test_score"]
    prob = sigmoid(z)
    patient["probability"] = prob

# Standard threshold vs. conservative threshold
standard_threshold = 0.5
conservative_threshold = 0.3  # Lower threshold = more cautious

print("Standard Threshold (0.5):")
for p in patients:
    decision = "REFER for further testing" if p["probability"] >= standard_threshold else "Monitor only"
    print(f"{p['name']}: {p['probability']:.3f} → {decision}")

print("\nConservative Threshold (0.3):")
for p in patients:
    decision = "REFER for further testing" if p["probability"] >= conservative_threshold else "Monitor only"
    print(f"{p['name']}: {p['probability']:.3f} → {decision}")

Output:

Standard Threshold (0.5):
Patient 1: 0.182 → Monitor only
Patient 2: 0.690 → REFER for further testing
Patient 3: 0.909 → REFER for further testing

Conservative Threshold (0.3):
Patient 1: 0.182 → Monitor only
Patient 2: 0.690 → REFER for further testing
Patient 3: 0.909 → REFER for further testing

Why this approach: In medical contexts, the cost of a false negative (missing a disease) is typically much higher than the cost of a false positive (an extra test). By lowering the threshold to 0.3, they catch more potential cases at the cost of more follow-up tests. This is called being "high sensitivity"—prioritizing catching all true positives even if it means more false alarms.

The outcome: With the conservative threshold, even patients with moderate confidence scores get referred for further testing, ensuring fewer diseases are missed. The hospital accepts the cost of extra testing to minimize the risk of missing serious conditions.

Caution: Some beginners think "just always use threshold=0.5 because it's the default." The right threshold depends entirely on the relative costs of false positives versus false negatives in your specific application. In medical diagnosis, spam detection, and fraud detection, you'll often want asymmetric thresholds based on which type of error is more costly.

4. Common Pitfalls: What Can Go Wrong and How to Avoid It
Note: These aren't just mistakes to avoid—they're learning opportunities to deepen your understanding.

The Mistake: Trying to use linear regression for classification and then rounding predictions to 0 or 1
Why It's a Problem: Linear regression can output values like -0.5 or 1.8, which round to 0 and 2 respectively. More critically, the model is trained to minimize squared error between predicted numbers and actual numbers, not to maximize classification accuracy. This means the learned line often crosses the 0.5 threshold in the wrong places, misclassifying many examples.
The Right Approach: Use logistic regression, which applies the sigmoid function and is trained using log loss (also called cross-entropy loss) that directly optimizes classification probability accuracy.
Why This Works: The sigmoid ensures outputs are valid probabilities, and the log loss function penalizes confident wrong predictions heavily, forcing the model to learn decision boundaries that actually separate classes well.
The Mistake: Assuming threshold=0.5 is always the right choice
Why It's a Problem: In imbalanced datasets (e.g., 95% non-fraud, 5% fraud) or when false positives and false negatives have different costs, a 0.5 threshold is often suboptimal. You might miss most fraud cases or flag too many legitimate transactions.
The Right Approach: After training your model, evaluate different thresholds on a validation set. Plot a precision-recall curve or ROC curve to see the tradeoffs, then choose the threshold that aligns with your business priorities (e.g., "we can tolerate 10% false positive rate to catch 95% of fraud").
Why This Works: The model learns to output well-calibrated probabilities during training. Threshold tuning is a separate post-training step that lets you customize the decision policy without retraining, aligning the model's behavior with your specific cost structure.
The Mistake: Interpreting the raw z-score as the final prediction
Why It's a Problem: Beginners sometimes see z = 2.5 and think "that's the prediction." But z is unbounded and not a probability. Without the sigmoid transformation, you can't interpret confidence or apply meaningful thresholds.
The Right Approach: Always pass z through the sigmoid function to get a probability: prob = sigmoid(z). Only this probability value (between 0 and 1) is interpretable as confidence.
Why This Works: The sigmoid is specifically designed to map the entire real number line to the [0,1] interval in a smooth, differentiable way that has nice mathematical properties for optimization and interpretation.
The Mistake: Thinking the decision boundary is set during training
Why It's a Problem: This leads to confusion when you need to adjust the threshold later. The model's parameters (weights and bias) are fixed after training, but the threshold is a hyperparameter you can adjust anytime without retraining.
The Right Approach: Understand that training learns P(y=1|x)—the probability function. The decision boundary location (where z=0) is learned, but the probability threshold for classification (e.g., "predict 1 if P ≥ 0.6") is chosen afterward based on your application's needs.
Why This Works: This separation allows you to train one model once, then deploy it with different thresholds for different use cases (e.g., conservative threshold for high-stakes decisions, aggressive threshold for low-stakes ones).
If you're stuck: Review Section 2 on how the sigmoid function works, and remember that z is the "raw score," sigmoid(z) is the "probability," and threshold is your "decision rule." These are three separate, sequential steps.

5. Your Turn: Practice & Self-Assessment
Practice Task (Estimated: 15-20 minutes)
The Challenge: You're building a credit approval system. Your trained logistic regression model uses two features: credit_score and income (in thousands). The model has learned these parameters: z = -5 + 0.02×credit_score + 0.03×income.

Write code to:

Create a function that predicts approval probability for a given applicant
Evaluate three applicants with different profiles:
Applicant A: credit_score=600, income=45
Applicant B: credit_score=720, income=68
Applicant C: credit_score=550, income=120
Make approval decisions using both threshold=0.5 and threshold=0.7
Explain which threshold you'd recommend and why
Specifications:

Yourpredict_probabilityfunction should take credit_score and income as inputs and return a probability
Print each applicant's z-score, probability, and decision for both thresholds
Include a 2-3 sentence justification for your threshold recommendation considering the costs of approving a risky applicant vs. denying a good applicant
Hint: Start by implementing the sigmoid function (you can reuse the one from Example 1). Then create the predict_probability function that calculates z using the given formula, then applies sigmoid. Think about which type of error is more costly in lending: giving credit to someone who defaults, or denying credit to someone who would repay successfully.

Extension (optional): Calculate at what income level Applicant C (credit_score=550) would need to reach probability=0.7. This involves algebraically solving for income when z produces sigmoid(z)=0.7.

Check Your Understanding
Answer these questions to verify you've grasped the key concepts:

Explanation question: Explain in your own words why we use the sigmoid function in logistic regression. What problem does it solve that linear regression can't handle?

Application question: You're building a spam filter. Would you use a higher threshold (e.g., 0.8) or lower threshold (e.g., 0.3)? Explain your reasoning considering what happens with false positives (legitimate emails marked as spam) versus false negatives (spam getting through).

Error analysis: Look at this code snippet:

z = 2.5
prediction = 1 if z > 0 else 0

What's wrong with this approach for logistic regression, and how would you fix it?

Transfer question: Your model predicts purchase probability for website visitors. Most visitors don't buy (95% don't buy, 5% do). You're using threshold=0.5 and barely catching any buyers. How would you use what you've learned to improve this?

Answers & Explanations:

The sigmoid function solves the problem that linear regression outputs unbounded values (any real number), which can't be interpreted as probabilities. Classification requires predictions between 0 and 1 that represent confidence. The sigmoid transforms any input z into a valid probability by using the formula 1/(1+e^(-z)), which always outputs values between 0 and 1. This creates an S-shaped curve where extreme inputs (very negative or very positive z) give probabilities near 0 or 1, while z=0 gives exactly 0.5 (maximum uncertainty).

For a spam filter, you should use a higher threshold (e.g., 0.7 or 0.8). This is because false positives (legitimate emails incorrectly marked as spam) are very costly—users might miss important messages from family, work, or financial institutions. False negatives (spam getting through) are annoying but less damaging—users can manually delete spam. A higher threshold means you only mark something as spam when you're very confident (≥70-80%), reducing the risk of incorrectly filtering important emails even if it means more spam gets through.

The code skips the sigmoid function entirely and makes decisions based on the raw z-score. This loses all probability information and uses z=0 as the threshold, which means the code can't be adjusted for different business needs. The fix:

z = 2.5
probability = sigmoid(z)  # First convert to probability
prediction = 1 if probability >= 0.5 else 0  # Then apply threshold

Now you have an interpretable probability (0.924 in this case) and can easily adjust the threshold without changing the model.

This is a classic imbalanced class problem. With 95% non-buyers and threshold=0.5, the model's probabilities for most actual buyers might be in the 0.2-0.4 range (since buyers are rare, the model is cautious). Lower your threshold to 0.2-0.3 so you catch more buyers. You'll get more false positives (showing offers to non-buyers), but in e-commerce, showing an extra offer to someone who won't buy is cheap, while missing a potential buyer is lost revenue. Test different thresholds on validation data to find where you maximize actual conversions without overwhelming users with too many popups.

Self-Assessment Checklist
You've mastered this topic if you can:

 Explain why linear regression fails for classification and how the sigmoid function solves that problem
 Calculate probabilities using the sigmoid function given any z-score, and understand that z=0 always maps to probability=0.5
 Apply different thresholds to probabilities and explain which threshold is appropriate for different business contexts
 Distinguish between the model's learned parameters (weights/bias), the z-score (linear combination), the probability (after sigmoid), and the threshold (decision rule)
 Predict how changing the threshold affects the types of errors (false positives vs. false negatives) your model makes
 Implement a complete logistic regression prediction pipeline: calculate z, apply sigmoid, apply threshold
If you checked fewer than 5 boxes: Review Section 3's worked examples, paying special attention to how we separately calculate z, apply sigmoid, then apply threshold. Try running the code yourself and modifying the thresholds to see how decisions change. If you're confused about when to use different thresholds, revisit Example 3 (medical diagnosis) to see the cost-based reasoning.

6. Consolidation: Key Takeaways & Next Steps
The Essential Ideas
The sigmoid converts unbounded scores to probabilities: It takes any real number (positive, negative, or zero) and squashes it into the range [0, 1], making the output interpretable as "confidence this belongs to class 1."
Threshold tuning is separate from model training: The model learns to output probabilities; you choose the decision threshold afterward based on your application's tolerance for different types of errors.
Lower thresholds make more positive predictions, higher thresholds make fewer: This is your tool for balancing false positives (incorrect "yes" predictions) against false negatives (missed "yes" cases) based on which is more costly in your domain.
Mental Model Check
By now, you should think of logistic regression as a three-stage pipeline: (1) Calculate a raw "evidence score" z from your features → (2) Transform that score into a probability using the sigmoid function → (3) Compare that probability to your chosen threshold to make a final yes/no decision. The first two stages are fixed after training; only the third stage (threshold) is adjustable in production.

What You Can Now Do
You can now build probabilistic classification systems that output confidence scores rather than just hard decisions. You understand how to tune these systems for different business contexts—making them more conservative when mistakes are costly, or more aggressive when you can tolerate false alarms. This foundation prepares you for understanding more complex classifiers and multi-class problems.

Next Steps
To deepen this knowledge: Practice implementing logistic regression from scratch using gradient descent, or experiment with different threshold values on a real dataset (like the Titanic survival dataset) to see how precision and recall change.

To build on this: Learn about multi-class classification using softmax (the generalization of sigmoid to more than two classes), or explore how logistic regression extends to neural networks by stacking multiple sigmoid layers.

Additional resources: For mathematical details on how logistic regression training works (gradient descent with log loss), see the StatQuest video "Logistic Regression Details Pt1: Coefficients" which visualizes the optimization process clearly.

Quick Reference Card
Concept	Formula / Key Idea	Range
Linear score (z)	z = w₁x₁ + w₂x₂ + ... + b	(-∞, +∞)
Sigmoid function	σ(z) = 1 / (1 + e^(-z))	[0, 1]
Key sigmoid values	σ(-∞)→0, σ(0)=0.5, σ(+∞)→1	Probabilities
Decision rule	Predict 1 if σ(z) ≥ threshold, else 0	Threshold: typically 0.3-0.7
Decision boundary	Located where z = 0 (when σ(z) = 0.5)	Learned during training
Threshold tuning principle	Higher threshold → fewer positives, fewer false positives
Lower threshold → more positives, fewer false negatives	Adjusted based on cost of errors
Quick decision guide for threshold selection:

High cost of false negatives (missing important cases) → Use lower threshold (0.3-0.4)
High cost of false positives (false alarms expensive) → Use higher threshold (0.6-0.8)
Balanced costs → Start with 0.5 and adjust based on validation metrics
Questions or stuck? Review the worked examples in Section 3, especially Example 2 (threshold tuning) and Example 3 (real-world medical application). Try modifying the code to see how different thresholds affect decisions. Remember: classification is about making informed decisions under uncertainty—the sigmoid gives you the "informed" part (probabilities), and the threshold lets you customize the "decision" part for your specific needs.

Classroom notes shared by the professor: Please find the .ipynb file in the attached zip file.
Logistic-regression